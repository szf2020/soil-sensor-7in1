#!/usr/bin/env python3
"""
JXCT Clang-Tidy Analysis Script
–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é clang-tidy –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
"""

import os
import subprocess
import shutil
import json
import datetime
from pathlib import Path
from collections import defaultdict

def run_clang_tidy(file_path):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç clang-tidy –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        # Resolve clang-tidy binary cross-platform: prefer PATH, fallback to Windows default
        clang_tidy_bin = shutil.which("clang-tidy") or "C:\\Program Files\\LLVM\\bin\\clang-tidy.exe"
        cmd = [
            clang_tidy_bin,
            file_path,
            "--quiet",
            "--format-style=file"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30, encoding='utf-8', errors='ignore')
        return {
            'file': file_path,
            'returncode': result.returncode,
            'stdout': result.stdout or '',
            'stderr': result.stderr or ''
        }
    except subprocess.TimeoutExpired:
        return {
            'file': file_path,
            'returncode': -1,
            'stdout': '',
            'stderr': 'Timeout expired'
        }
    except Exception as e:
        return {
            'file': file_path,
            'returncode': -1,
            'stdout': '',
            'stderr': str(e)
        }

def parse_warnings(output):
    """–ü–∞—Ä—Å–∏—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è clang-tidy"""
    if not output:
        return []

    warnings = []
    lines = output.split('\n')

    for line in lines:
        if 'warning:' in line and '.cpp:' in line:
            parts = line.split('warning:')
            if len(parts) >= 2:
                location = parts[0].strip()
                warning_text = parts[1].strip()
                warnings.append({
                    'location': location,
                    'warning': warning_text
                })

    return warnings

def categorize_warnings(warnings):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º"""
    categories = defaultdict(list)

    for warning in warnings:
        warning_text = warning['warning']

        if 'readability-' in warning_text:
            categories['–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å'].append(warning)
        elif 'modernize-' in warning_text:
            categories['–ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è'].append(warning)
        elif 'bugprone-' in warning_text:
            categories['–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –±–∞–≥–∏'].append(warning)
        elif 'misc-' in warning_text:
            categories['–†–∞–∑–Ω–æ–µ'].append(warning)
        elif 'cert-' in warning_text:
            categories['–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'].append(warning)
        else:
            categories['–ü—Ä–æ—á–µ–µ'].append(warning)

    return categories

def generate_report(results):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown"""
    report = []
    report.append("# CLANG-TIDY –ü–û–õ–ù–´–ô –û–¢–ß–Å–¢ –ê–ù–ê–õ–ò–ó–ê")
    report.append(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {datetime.datetime.now().strftime('%d.%m.%Y %H:%M')}")
    report.append(f"**–í–µ—Ä—Å–∏—è clang-tidy:** 20.1.0")
    report.append("")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_files = len(results)
    successful_files = sum(1 for r in results if r['returncode'] == 0 or r['returncode'] == 1)
    failed_files = total_files - successful_files

    total_warnings = 0
    all_warnings = []

    for result in results:
        if result['returncode'] in [0, 1]:  # 0 = –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º, 1 = –µ—Å—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            warnings = parse_warnings(result['stdout'])
            total_warnings += len(warnings)
            all_warnings.extend(warnings)

    report.append("## üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    report.append(f"- **–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** {total_files}")
    report.append(f"- **–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** {successful_files}")
    report.append(f"- **–û—à–∏–±–∫–∏ –∞–Ω–∞–ª–∏–∑–∞:** {failed_files}")
    report.append(f"- **–í—Å–µ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π:** {total_warnings}")
    report.append("")

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
    categories = categorize_warnings(all_warnings)

    report.append("## üîç –ö–ê–¢–ï–ì–û–†–ò–ò –ü–†–û–ë–õ–ï–ú")
    for category, warnings in categories.items():
        report.append(f"### {category} ({len(warnings)} –ø—Ä–æ–±–ª–µ–º)")

        # –¢–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        warning_counts = defaultdict(int)
        for warning in warnings:
            warning_type = warning['warning'].split('[')[1].split(']')[0] if '[' in warning['warning'] else 'unknown'
            warning_counts[warning_type] += 1

        top_warnings = sorted(warning_counts.items(), key=lambda x: x[1], reverse=True)[:5]

        for warning_type, count in top_warnings:
            report.append(f"- `{warning_type}`: {count} —Å–ª—É—á–∞–µ–≤")

        report.append("")

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ñ–∞–π–ª–∞–º
    report.append("## üìÅ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û –§–ê–ô–õ–ê–ú")

    for result in results:
        if result['returncode'] in [0, 1]:
            warnings = parse_warnings(result['stdout'])

            if warnings:
                report.append(f"### {result['file']} ({len(warnings)} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π)")

                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
                file_categories = categorize_warnings(warnings)

                for category, category_warnings in file_categories.items():
                    if category_warnings:
                        report.append(f"**{category}:** {len(category_warnings)} –ø—Ä–æ–±–ª–µ–º")

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
                        for i, warning in enumerate(category_warnings[:3]):
                            report.append(f"- {warning['location']}: {warning['warning']}")

                        if len(category_warnings) > 3:
                            report.append(f"- ... –∏ –µ—â—ë {len(category_warnings) - 3} –ø—Ä–æ–±–ª–µ–º")

                        report.append("")
            else:
                report.append(f"### {result['file']} ‚úÖ –ü—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                report.append("")
        else:
            report.append(f"### {result['file']} ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
            report.append(f"```")
            report.append(result['stderr'])
            report.append(f"```")
            report.append("")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    report.append("## üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ü–†–ò–û–†–ò–¢–ï–¢–ê–ú")
    report.append("")
    report.append("### üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï (–∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ)")
    if '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –±–∞–≥–∏' in categories:
        report.append("- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –±–∞–≥–∏ - –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç–µ")
    if '–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å' in categories:
        report.append("- –ü—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ - –º–æ–≥—É—Ç —Å–æ–∑–¥–∞—Ç—å —É—è–∑–≤–∏–º–æ—Å—Ç–∏")
    report.append("")

    report.append("### üü° –°–†–ï–î–ù–ò–ï (–∏—Å–ø—Ä–∞–≤–∏—Ç—å –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è)")
    if '–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å' in categories:
        report.append("- –ü—Ä–æ–±–ª–µ–º—ã —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ - –∑–∞—Ç—Ä—É–¥–Ω—è—é—Ç —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ –∫–æ–¥–∞")
    if '–ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è' in categories:
        report.append("- –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è - —É–ª—É—á—à–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞")
    report.append("")

    report.append("### üü¢ –ù–ò–ó–ö–ò–ï (–º–æ–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ)")
    if '–†–∞–∑–Ω–æ–µ' in categories:
        report.append("- –†–∞–∑–Ω—ã–µ –º–µ–ª–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
    if '–ü—Ä–æ—á–µ–µ' in categories:
        report.append("- –ü—Ä–æ—á–∏–µ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è")
    report.append("")

    return '\n'.join(report)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ clang-tidy...")

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ .cpp —Ñ–∞–π–ª—ã
    cpp_files = []
    for root, dirs, files in os.walk('src'):
        for file in files:
            if file.endswith('.cpp'):
                cpp_files.append(os.path.join(root, file).replace('\\', '/'))

    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(cpp_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    results = []
    for i, file_path in enumerate(cpp_files, 1):
        print(f"‚è≥ –ê–Ω–∞–ª–∏–∑ {i}/{len(cpp_files)}: {file_path}")
        result = run_clang_tidy(file_path)
        results.append(result)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
    print("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞...")
    report = generate_report(results)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç
    report_path = 'test_reports/clang_tidy_analysis_report.md'
    os.makedirs(os.path.dirname(report_path), exist_ok=True)

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    json_path = 'test_reports/clang_tidy_analysis_data.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print(f"üìÑ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")
    print(f"üîß –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {json_path}")

    # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_warnings = 0
    for result in results:
        if result['returncode'] in [0, 1]:
            warnings = parse_warnings(result['stdout'])
            total_warnings += len(warnings)

    print(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {total_warnings}")

if __name__ == "__main__":
    main()
